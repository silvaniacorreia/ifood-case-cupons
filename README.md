# iFood Case â€“ Cupons

Case para vaga de Analista de Dados no iFood, com o objetivo de analisar um **teste A/B** de uma estratÃ©gia de **cupons** com foco em **retenÃ§Ã£o** e crescimento.

**O case solicita que a entrega contemple, na ordem, os itens abaixo:**

1) **Teste A/B (Campanha de Cupons)**
   - **(a)** Definir **indicadores/mÃ©tricas de sucesso** da campanha e analisar se houve **impacto estatisticamente significativo** no perÃ­odo avaliado.
   - **(b)** Realizar **anÃ¡lise de viabilidade financeira** (ex.: ROI / payback), **explicitando as premissas** adotadas.
   - **(c)** Recomendar **oportunidades de melhoria** na aÃ§Ã£o e **desenhar um novo teste A/B** para validar as hipÃ³teses (desenho experimental, mÃ©tricas e guardrails).

2) **SegmentaÃ§Ã£o de UsuÃ¡rios**
   - **(a)** Estabelecer **critÃ©rios/ regras** para cada **segmento** (ex.: RFM), **explicando o racional** da construÃ§Ã£o.
   - **(b)** Analisar os **resultados do A/B por segmento** e **propor aÃ§Ãµes especÃ­ficas** para cada pÃºblico.

3) **RecomendaÃ§Ãµes e PrÃ³ximos Passos**
   - Sugerir **prÃ³ximos passos** com **previsÃ£o de impacto** (financeiro ou nÃ£o), defendendo as recomendaÃ§Ãµes para as **lideranÃ§as de NegÃ³cio**.
   - Incluir **melhorias de processo/teste** e **estratÃ©gias diferenciadas por segmento**.  
   - Quando necessÃ¡rio, **adotar premissas** e **deixÃ¡-las claras** no material.

<a href="https://colab.research.google.com/github/silvaniacorreia/ifood-case-cupons/blob/main/notebooks/00_setup_and_checks.ipynb" target="_blank" rel="noopener">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab">
</a>

> **O que este repositÃ³rio entrega agora:** bootstrap reprodutÃ­vel (local e Colab), **download programÃ¡tico** + extraÃ§Ã£o, inicializaÃ§Ã£o do **PySpark** e **smoke test**. As etapas de ETL, RFM, A/B e ROI estÃ£o sendo adicionadas na sequÃªncia.

> **Como executar (avaliadores):** abra e rode **um notebook por vez na ordem** â†’ `00_setup_and_checks` â†’ `01_etl_pyspark` â†’ `02_abtest_and_segments` â†’ `03_financial_roi`.

---

## âœ… Status (parcial)

- **Download programÃ¡tico** e extraÃ§Ã£o (`scripts/download_data.py`) lendo as fontes de `config/settings.yaml`.
- **Bootstrap Colab/Local** em `notebooks/00_setup_and_checks.ipynb`:
  - Colab: clona o repositÃ³rio, instala dependÃªncias, baixa e prepara os dados.
  - Local: verifica paths e roda o mesmo script de download.
- **UtilitÃ¡rios** (`src/utils.py`): `load_settings`, `get_spark`, `set_seeds`, `stop_spark`.
- **Smoke test** do Spark no `00_setup_and_checks.ipynb`.

> Em construÃ§Ã£o: `src/etl.py`, `src/segments.py` (RFM), `src/abtest.py`, `src/finance.py` + notebooks `01_`, `02_`, `03_`.

---

## ğŸ§© Estrutura do repositÃ³rio

```markdown
ifood-case-cupons/
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ Makefile
â”œâ”€ notebooks/
â”‚  â”œâ”€ 00_setup_and_checks.ipynb      # bootstrap + download programÃ¡tico + smoke do Spark
â”‚  â”œâ”€ 01_etl_pyspark.ipynb           # (em construÃ§Ã£o)
â”‚  â”œâ”€ 02_abtest_and_segments.ipynb   # (em construÃ§Ã£o)
â”‚  â””â”€ 03_financial_roi.ipynb         # (em construÃ§Ã£o)
â”œâ”€ src/
â”‚  â”œâ”€ __init__.py
â”‚  â””â”€ utils.py                       # settings + spark + seeds
â”œâ”€ scripts/
â”‚  â””â”€ download_data.py               # baixa .gz/.tar.gz e extrai o .tar.gz
â”œâ”€ config/
â”‚  â”œâ”€ settings.example.yaml
â”‚  â””â”€ settings.yaml                  # contÃ©m o bloco `sources:` com as URLs
â”œâ”€ data/
â”‚  â”œâ”€ raw/                           # arquivos baixados (spark lÃª .gz direto)
â”‚  â””â”€ processed/                     # saÃ­das intermediÃ¡rias (parquet)
â””â”€ report/
```

## âš™ï¸ ConfiguraÃ§Ã£o

Arquivo: `config/settings.yaml`

ParÃ¢metros do projeto (seed, spark, caminhos) e bloco `sources` com as URLs e nomes dos 4 arquivos do case:

```yaml
sources:
  orders:      { url: ".../order.json.gz",      filename: "order.json.gz" }
  consumers:   { url: ".../consumer.csv.gz",    filename: "consumer.csv.gz" }
  restaurants: { url: ".../restaurant.csv.gz",  filename: "restaurant.csv.gz" }
  ab_test_ref: { url: ".../ab_test_ref.tar.gz", filename: "ab_test_ref.tar.gz" }
```

O `scripts/download_data.py` lÃª essas entradas, baixa os arquivos para `data/raw/` e extrai o `ab_test_ref.tar.gz` para `data/raw/ab_test_ref_extracted/`. Os `.gz` (JSON/CSV) nÃ£o precisam ser descompactados para o Spark.

---

## â–¶ï¸ Como executar no Colab (avaliadores)

Clique no badge acima (â€œOpen in Colabâ€).

No Colab, vÃ¡ em `Runtime â†’ Run all (Executar tudo)`.

A primeira cÃ©lula:
- clona este repositÃ³rio para `/content/ifood-case-cupons`,
- instala dependÃªncias do `requirements.txt`,
- roda `scripts/download_data.py` (download programÃ¡tico + extraÃ§Ã£o).

A segunda cÃ©lula faz o smoke test do Spark (deve imprimir â€œSpark OK: x.y.zâ€ e exibir uma tabela 0..4).

ApÃ³s isso, os dados estarÃ£o em:

```
/content/ifood-case-cupons/data/raw/
/content/ifood-case-cupons/data/raw/ab_test_ref_extracted/
```

Quando os notebooks seguintes forem concluÃ­dos, basta abrir `01_`, `02_` e `03_` e executar normalmente.

---

## ğŸ’» Como executar localmente (desenvolvedores)

PrÃ©-requisitos: Python 3.10+, JDK 11+ (para Spark).

```bash
# 1) Ambiente
python -m venv .venv && source .venv/bin/activate      # Windows: .venv\Scripts\activate
pip install -r requirements.txt
python -m ipykernel install --user --name ifood-case

# 2) Download programÃ¡tico
python scripts/download_data.py

# 3) Jupyter
jupyter notebook   # ou jupyter lab
# Abra notebooks/00_setup_and_checks.ipynb e rode "Run all"
```

Se aparecer erro de Java local, instale um JDK 11+ e confira `java -version` no terminal.

---

## ğŸ§ª Teste rÃ¡pido (smoke do Spark)

No `notebooks/00_setup_and_checks.ipynb` jÃ¡ existe uma cÃ©lula que faz:

```python
from src.utils import load_settings, set_seeds, get_spark, stop_spark
s = load_settings()
set_seeds(s.runtime.seed)
spark = get_spark(app_name=s.runtime.spark.app_name,
                  shuffle_partitions=s.runtime.spark.shuffle_partitions)
print("Spark OK:", spark.version)
spark.range(5).show()
stop_spark(spark)
```

---

## ğŸ”œ Roadmap (prÃ³ximas entregas)

- `src/etl.py` + `notebooks/01_etl_pyspark.ipynb`
- `src/segments.py` (RFM) + `notebooks/02_abtest_and_segments.ipynb`
- `src/abtest.py` (A/B com CUPED) + `src/finance.py` (ROI) + `notebooks/03_financial_roi.ipynb`

