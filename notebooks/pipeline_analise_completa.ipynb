{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe50670",
   "metadata": {},
   "source": [
    "# Análise Completa - Case Ifood: Teste A/B Estratégia de Cupons\n",
    "\n",
    "Notebook único para orquestrar as tarefas de execução de *setup*, **ETL** e análise dos dados, integrando os diferentes módulos do repositório de origem:\n",
    "\n",
    "- Clona/atualiza o repositório do projeto, com as dependências, no Colab\n",
    "- Instala dependências e faz o **download** dos dados brutos\n",
    "- Sobe Spark e executa o **ETL** (orders/consumers/restaurants + mapa A/B)\n",
    "- Mantém `orders_silver` e `users_silver` em memória\n",
    "- Realiza a análise exploratória dos dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc5c4c",
   "metadata": {},
   "source": [
    "## Configuração de Ambiente e Download de Dados Brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daddc1e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "GITHUB_USER = \"silvaniacorreia\"\n",
    "REPO_NAME   = \"ifood-case-cupons\"\n",
    "REPO_URL    = f\"https://github.com/{GITHUB_USER}/{REPO_NAME}.git\"\n",
    "assert \"COLAB_RELEASE_TAG\" in os.environ or \"COLAB_GPU\" in os.environ, \"Este notebook foi preparado para executar no Google Colab.\"\n",
    "\n",
    "def run(cmd):\n",
    "    print(\">\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "# 1) clonar/atualizar repositório\n",
    "ROOT = Path(\"/content\")\n",
    "PROJECT_DIR = ROOT / REPO_NAME\n",
    "if not PROJECT_DIR.exists():\n",
    "    run([\"git\", \"clone\", REPO_URL, str(PROJECT_DIR)])\n",
    "else:\n",
    "    os.chdir(PROJECT_DIR)\n",
    "    run([\"git\", \"fetch\", \"--all\"])\n",
    "    run([\"git\", \"checkout\", \"main\"])\n",
    "    run([\"git\", \"pull\", \"--rebase\", \"origin\", \"main\"])\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "# 2) deps + download programático (idempotentes)\n",
    "run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
    "run([sys.executable, \"scripts/download_data.py\"])\n",
    "\n",
    "# 3) sys.path\n",
    "if str(PROJECT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_DIR))\n",
    "print(\"✔️ Bootstrap concluído. Projeto:\", PROJECT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f4bcb",
   "metadata": {},
   "source": [
    "## Iniciando o Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66ab3e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import load_settings, get_spark\n",
    "\n",
    "s = load_settings()\n",
    "spark = get_spark(\n",
    "    app_name=s.runtime.spark.app_name,\n",
    "    shuffle_partitions=s.runtime.spark.shuffle_partitions,\n",
    "    extra_conf=getattr(s.runtime.spark, \"conf\", {}) \n",
    ")\n",
    "print(\"✔️ Spark ativo - versão:\", spark.version)\n",
    "\n",
    "# checagem rápida\n",
    "spark.range(5).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5aaf2e",
   "metadata": {},
   "source": [
    "## Análises Pré-Flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc9f02",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Pré-flight (checagens dados brutos)\n",
    "from src.checks import preflight\n",
    "from pprint import pprint\n",
    "\n",
    "rep = preflight(s.data.raw_dir, strict=False)\n",
    "print(\"Pré-flight (resumo):\")\n",
    "pprint({\n",
    "    \"raw_dir\": rep[\"raw_dir\"],\n",
    "    \"orders_format_guess\": rep[\"orders_format_guess\"],\n",
    "    \"files\": {k: {kk: vv for kk, vv in v.items() if kk in (\"exists\",\"size_bytes\",\"gzip_ok\",\"tar_ok\")} for k, v in rep[\"files\"].items()},\n",
    "    \"ab_csv_candidates\": rep[\"ab_csv_candidates\"][:3],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc2464",
   "metadata": {},
   "source": [
    "## ETL (Extração, Transformação e Carga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c1918c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src import etl, checks\n",
    "from pyspark.sql import functions as F\n",
    "import importlib, os\n",
    "\n",
    "# 1) ler brutos\n",
    "orders, consumers, restaurants, abmap = etl.load_raw(spark, s.data.raw_dir)\n",
    "checks.profile_loaded(orders, consumers, restaurants, abmap, n=5)\n",
    "\n",
    "# 2) conform + joins + janela\n",
    "df = etl.clean_and_conform(\n",
    "    orders, consumers, restaurants, abmap,\n",
    "    business_tz=getattr(s.analysis, \"business_tz\", \"America/Sao_Paulo\"),\n",
    "    treat_is_target_null_as_control=getattr(s.analysis, \"treat_is_target_null_as_control\", False),\n",
    "    experiment_start=getattr(getattr(s, \"analysis\", {}), \"experiment_window\", {}).get(\"start\") if getattr(s, \"analysis\", None) and getattr(s.analysis, \"experiment_window\", None) else None,\n",
    "    experiment_end=getattr(getattr(s, \"analysis\", {}), \"experiment_window\", {}).get(\"end\") if getattr(s, \"analysis\", None) and getattr(s.analysis, \"experiment_window\", None) else None,\n",
    "    auto_infer_window=getattr(s.analysis, \"auto_infer_window\", True),\n",
    ")\n",
    "\n",
    "# 3) silvers em memória\n",
    "orders_silver = etl.build_orders_silver(df)\n",
    "users_silver  = etl.build_user_aggregates(orders_silver)\n",
    "\n",
    "# recency com base no último timestamp observado\n",
    "ref_ts = orders_silver.agg(F.max(\"event_ts_utc\")).first()[0]\n",
    "users_silver = users_silver.withColumn(\n",
    "    \"recency\",\n",
    "    F.when(F.col(\"last_order\").isNotNull(), F.datediff(F.lit(ref_ts), F.col(\"last_order\")))\n",
    ")\n",
    "\n",
    "# 4) salvar parquet localmente\n",
    "SAVE_PARQUET = True\n",
    "if SAVE_PARQUET:\n",
    "    spark.catalog.clearCache()\n",
    "    orders_silver.coalesce(4).write.mode(\"overwrite\").parquet(f\"{s.data.processed_dir}/orders_silver.parquet\")\n",
    "    users_silver.coalesce(4).write.mode(\"overwrite\").parquet(f\"{s.data.processed_dir}/users_silver.parquet\")\n",
    "\n",
    "print(\"orders_silver:\", orders_silver.count(), \"linhas\")\n",
    "print(\"users_silver :\", users_silver.count(), \"linhas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b8d32d",
   "metadata": {},
   "source": [
    "## Checagem dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4388b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Checks essenciais (nulos, janela, split A/B) ---\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def nulls_by_col(df):\n",
    "    exprs = [F.sum(F.col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]\n",
    "    return df.select(exprs)\n",
    "\n",
    "print(\"Faixa de datas (UTC) em orders_silver:\")\n",
    "orders_silver.agg(F.min(\"event_ts_utc\").alias(\"min_utc\"),\n",
    "                  F.max(\"event_ts_utc\").alias(\"max_utc\")).show()\n",
    "\n",
    "print(\"Split A/B (users):\")\n",
    "users_silver.groupBy(\"is_target\").count().show()\n",
    "\n",
    "print(\"Nulos em orders_silver:\")\n",
    "nulls_by_col(orders_silver).show(truncate=False)\n",
    "\n",
    "# previews\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(orders_silver.limit(5).toPandas())\n",
    "    display(users_silver.limit(5).toPandas())\n",
    "except Exception:\n",
    "    print(\"Preview (head) orders_silver:\", orders_silver.limit(5).toPandas().head())\n",
    "    print(\"Preview (head) users_silver :\", users_silver.limit(5).toPandas().head())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
