{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe50670",
   "metadata": {},
   "source": [
    "# Análise Completa - Case Ifood: Teste A/B Estratégia de Cupons\n",
    "\n",
    "Notebook único para orquestrar as tarefas de execução de *setup*, **ETL** e análise dos dados, integrando os diferentes módulos do repositório de origem:\n",
    "\n",
    "- Clona/atualiza o repositório do projeto, com as dependências, no Colab\n",
    "- Instala dependências e faz o **download** dos dados brutos\n",
    "- Sobe Spark e executa o **ETL** (orders/consumers/restaurants + mapa A/B)\n",
    "- Mantém `orders_silver` e `users_silver` em memória\n",
    "- Realiza a análise exploratória dos dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46b6e4",
   "metadata": {},
   "source": [
    "## Configuração do Ambiente e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc5c4c",
   "metadata": {},
   "source": [
    "### Configuração de Ambiente e Download de Dados Brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daddc1e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "GITHUB_USER = \"silvaniacorreia\"\n",
    "REPO_NAME   = \"ifood-case-cupons\"\n",
    "REPO_URL    = f\"https://github.com/{GITHUB_USER}/{REPO_NAME}.git\"\n",
    "\n",
    "def run(cmd):\n",
    "    print(\">\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "# 1) clonar/atualizar repositório\n",
    "ROOT = Path(\"/content\")\n",
    "PROJECT_DIR = ROOT / REPO_NAME\n",
    "if not PROJECT_DIR.exists():\n",
    "    run([\"git\", \"clone\", REPO_URL, str(PROJECT_DIR)])\n",
    "else:\n",
    "    os.chdir(PROJECT_DIR)\n",
    "    run([\"git\", \"fetch\", \"--all\"])\n",
    "    run([\"git\", \"checkout\", \"main\"])\n",
    "    run([\"git\", \"pull\", \"--rebase\", \"origin\", \"main\"])\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "# 2) deps + download programático\n",
    "run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\", \"--no-cache-dir\"])\n",
    "run([sys.executable, \"scripts/download_data.py\"])\n",
    "\n",
    "# 3) sys.path\n",
    "if str(PROJECT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_DIR))\n",
    "print(\"✔️ Bootstrap concluído. Projeto:\", PROJECT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f4bcb",
   "metadata": {},
   "source": [
    "### Iniciando o Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66ab3e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import load_settings, get_spark\n",
    "\n",
    "s = load_settings()\n",
    "spark = get_spark(\n",
    "    app_name=s.runtime.spark.app_name,\n",
    "    shuffle_partitions=s.runtime.spark.shuffle_partitions,\n",
    "    extra_conf=getattr(s.runtime.spark, \"conf\", {}) \n",
    ")\n",
    "print(\"✔️ Spark ativo - versão:\", spark.version)\n",
    "\n",
    "# checagem rápida\n",
    "spark.range(5).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5aaf2e",
   "metadata": {},
   "source": [
    "### Análises Pré-Flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc9f02",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Checagens dados brutos\n",
    "from src.checks import preflight\n",
    "from pprint import pprint\n",
    "\n",
    "rep = preflight(s.data.raw_dir, strict=False)\n",
    "print(\"Pré-flight (resumo):\")\n",
    "pprint({\n",
    "    \"raw_dir\": rep[\"raw_dir\"],\n",
    "    \"orders_format_guess\": rep[\"orders_format_guess\"],\n",
    "    \"files\": {k: {kk: vv for kk, vv in v.items() if kk in (\"exists\",\"size_bytes\",\"gzip_ok\",\"tar_ok\")} for k, v in rep[\"files\"].items()},\n",
    "    \"ab_csv_candidates\": rep[\"ab_csv_candidates\"][:3],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc2464",
   "metadata": {},
   "source": [
    "### ETL (Extração, Transformação e Carga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c1918c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src import etl, checks\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "\n",
    "def _get_exp_window(s):\n",
    "    \"\"\"\n",
    "    Lê a janela do experimento a partir das configurações. Caso não exista, utiliza inferência automática.\n",
    "\n",
    "    Parâmetros:\n",
    "        s: Objeto de configurações carregado.\n",
    "\n",
    "    Retorna:\n",
    "        Tuple[str, str, bool]: Data de início, data de fim e flag de inferência automática.\n",
    "    \"\"\"\n",
    "    win = getattr(s.analysis, \"experiment_window\", None)\n",
    "    if isinstance(win, dict):\n",
    "        start = win.get(\"start\")\n",
    "        end   = win.get(\"end\")\n",
    "    else:\n",
    "        start = None\n",
    "        end   = None\n",
    "    auto = bool(getattr(s.analysis, \"auto_infer_window\", True))\n",
    "    return start, end, auto\n",
    "\n",
    "start, end, auto = _get_exp_window(s)\n",
    "\n",
    "# 1) Leitura dos dados brutos\n",
    "orders, consumers, restaurants, abmap = etl.load_raw(spark, s.data.raw_dir)\n",
    "checks.profile_loaded(orders, consumers, restaurants, abmap, n=5)\n",
    "\n",
    "# 2) Limpeza e conformidade dos dados\n",
    "# Inclui normalização de timezone e aplicação de janela experimental\n",
    "# Utiliza quantis para robustez contra outliers\n",
    "df = etl.clean_and_conform(\n",
    "    orders, consumers, restaurants, abmap,\n",
    "    business_tz=getattr(s.analysis, \"business_tz\", \"America/Sao_Paulo\"),\n",
    "    treat_is_target_null_as_control=getattr(s.analysis, \"treat_is_target_null_as_control\", False),\n",
    "    experiment_start=start,\n",
    "    experiment_end=end,\n",
    "    auto_infer_window=auto,\n",
    "    use_quantile_window=True,     # janela robusta a outliers\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 3) Ajustes finais e agregações para análise\n",
    "orders_silver = etl.build_orders_silver(df)\n",
    "orders_silver = etl.enrich_orders_for_analysis(orders_silver)\n",
    "users_silver  = etl.build_user_aggregates(orders_silver)\n",
    "\n",
    "# 4) Cálculo de recência com base no último timestamp observado\n",
    "ref_ts = orders_silver.agg(F.max(\"event_ts_utc\")).first()[0]\n",
    "users_silver = users_silver.withColumn(\"recency\", F.datediff(F.lit(ref_ts), F.col(\"last_order\")))\n",
    "\n",
    "# 5) Salvar resultados em formato Parquet (opcional)\n",
    "SAVE_PARQUET = False\n",
    "if SAVE_PARQUET:\n",
    "    (\n",
    "        orders_silver\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .partitionBy(\"event_date_brt\")\n",
    "        .parquet(f\"{s.data.processed_dir}/orders_silver.parquet\")\n",
    "    )\n",
    "    users_silver.write.mode(\"overwrite\").parquet(f\"{s.data.processed_dir}/users_silver.parquet\")\n",
    "\n",
    "# 6) Contagem de linhas para validação\n",
    "print(\"orders_silver:\", orders_silver.count(), \"linhas\")\n",
    "print(\"users_silver :\", users_silver.count(), \"linhas\")\n",
    "\n",
    "# 7) Exibição de amostras para validação\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(orders_silver.limit(5).toPandas())\n",
    "    display(users_silver.limit(5).toPandas())\n",
    "except Exception as e:\n",
    "    print(\"Aviso: toPandas falhou, mostrando via Spark .show()\")\n",
    "    orders_silver.show(5, truncate=False)\n",
    "    users_silver.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b8d32d",
   "metadata": {},
   "source": [
    "### Checagem dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d78d984",
   "metadata": {},
   "source": [
    "Foram investigadas duplicatas semânticas na fato (IDs diferentes com mesmo cliente/loja/tempo/valor). Como apenas 1 caso foi encontrado, o que gera efeito desprezível, não foi aplicada a deduplicação adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4388b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def check_post_etl(\n",
    "    orders_silver,\n",
    "    users_silver,\n",
    "    *,\n",
    "    light: bool = True,\n",
    "    key_cols: list[str] | None = None,\n",
    "    sample_frac: float = 0.001,\n",
    "    preview_rows: int = 5,\n",
    "    use_pandas_preview: bool = False,\n",
    "    check_semantic_dups: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Executa checagens leves pós-ETL para registro no Colab.\n",
    "    - light=True: nulos apenas em colunas-chave e previews por sample.\n",
    "    - light=False: nulos em todas as colunas (lento).\n",
    "    - check_semantic_dups: investiga duplicatas semânticas na fato (lento moderado).\n",
    "    \"\"\"\n",
    "    if key_cols is None:\n",
    "        key_cols = [\n",
    "            \"order_id\", \"customer_id\", \"merchant_id\",\n",
    "            \"event_ts_utc\", \"order_total_amount\",\n",
    "            \"is_target\", \"price_range\", \"language\", \"active\",\n",
    "            \"delivery_time_imputed\", \"minimum_order_value_imputed\",\n",
    "        ]\n",
    "    key_cols = [c for c in key_cols if c in orders_silver.columns]\n",
    "\n",
    "    print(\"Faixa de datas (UTC) em orders_silver:\")\n",
    "    orders_silver.agg(\n",
    "        F.min(\"event_ts_utc\").alias(\"min_utc\"),\n",
    "        F.max(\"event_ts_utc\").alias(\"max_utc\"),\n",
    "    ).show(truncate=False)\n",
    "\n",
    "    print(\"Split A/B (users):\")\n",
    "    users_silver.groupBy(\"is_target\").count().orderBy(\"is_target\").show()\n",
    "\n",
    "    # --- Nulos em orders_silver ---\n",
    "    def nulls_by_col(df, cols):\n",
    "        exprs = [F.sum(F.col(c).isNull().cast(\"int\")).alias(c) for c in cols]\n",
    "        return df.select(exprs)\n",
    "\n",
    "    if light:\n",
    "        print(f\"Nulos (colunas-chave): {key_cols}\")\n",
    "        nulls_by_col(orders_silver, key_cols).show(truncate=False)\n",
    "    else:\n",
    "        print(\"Nulos (todas as colunas) — operação pesada:\")\n",
    "        nulls_by_col(orders_silver, orders_silver.columns).show(truncate=False)\n",
    "\n",
    "    # --- Duplicatas semânticas (order_ids diferentes com mesmo cliente/restaurante/ts/valor) ---\n",
    "    if check_semantic_dups:\n",
    "        print(\"\\nPossíveis duplicatas sistêmicas (mesmo cliente/restaurante/ts/valor, order_id distinto):\")\n",
    "        dups = (\n",
    "            orders_silver\n",
    "            .groupBy(\"customer_id\", \"merchant_id\", \"event_ts_utc\", \"order_total_amount\")\n",
    "            .agg(\n",
    "                F.countDistinct(\"order_id\").alias(\"n_orders\"),\n",
    "                F.collect_set(\"order_id\").alias(\"order_ids\"),\n",
    "            )\n",
    "            .filter(F.col(\"n_orders\") > 1)\n",
    "        )\n",
    "        total_dups = dups.count()\n",
    "        print(f\"Total de combinações com múltiplos order_id: {total_dups}\")\n",
    "        if total_dups > 0:\n",
    "            dups.select(\"customer_id\",\"merchant_id\",\"event_ts_utc\",\"order_total_amount\",\"n_orders\",\"order_ids\")\\\n",
    "                .orderBy(F.col(\"n_orders\").desc())\\\n",
    "                .show(10, truncate=False)\n",
    "\n",
    "    # --- Previews rápidos ---\n",
    "    print(\"\\nPreview orders_silver (sample leve):\")\n",
    "    orders_preview_cols = [c for c in [\n",
    "        \"price_range\",\"order_id\",\"customer_id\",\"merchant_id\",\n",
    "        \"event_ts_utc\",\"order_total_amount\",\"origin_platform\",\n",
    "        \"is_target\",\"language\",\"active\"\n",
    "    ] if c in orders_silver.columns]\n",
    "    preview_df = orders_silver.sample(False, sample_frac, seed=42).select(*orders_preview_cols)\n",
    "    if preview_df.rdd.isEmpty():\n",
    "        preview_df = orders_silver.select(*orders_preview_cols).limit(preview_rows)\n",
    "    preview_df.show(preview_rows, truncate=False)\n",
    "\n",
    "    print(\"\\nPreview users_silver (primeiras linhas):\")\n",
    "    users_preview_cols = [c for c in [\n",
    "        \"customer_id\",\"last_order\",\"frequency\",\"monetary\",\"is_target\",\"recency\"\n",
    "    ] if c in users_silver.columns]\n",
    "    users_silver.select(*users_preview_cols).show(preview_rows, truncate=False)\n",
    "\n",
    "    if use_pandas_preview:\n",
    "        try:\n",
    "            from IPython.display import display\n",
    "            display(orders_silver.limit(preview_rows).toPandas())\n",
    "            display(users_silver.limit(preview_rows).toPandas())\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# --- Executar em modo leve ---\n",
    "check_post_etl(orders_silver, users_silver, light=True, check_semantic_dups=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db6755",
   "metadata": {},
   "source": [
    "## A/B de cupons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d1372",
   "metadata": {},
   "source": [
    "### Importações e Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd0ecbb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from src.analysis_ab import (\n",
    "    compute_ab_summary,\n",
    "    compute_robust_metrics,\n",
    "    collect_user_level_for_tests,\n",
    "    run_ab_tests,\n",
    "    run_nonparam_tests,\n",
    "    financial_viability\n",
    ")\n",
    "from src.utils import load_settings\n",
    "settings = load_settings(\"config/settings.yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe62f8c6",
   "metadata": {},
   "source": [
    "### Visualizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d6442",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "users_pdf = collect_user_level_for_tests(users_silver)\n",
    "\n",
    "# Boxplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "sns.boxplot(x=\"is_target\", y=\"monetary\", data=users_pdf, ax=axes[0])\n",
    "axes[0].set_title(\"GMV por Usuário\")\n",
    "axes[0].set_xticklabels([\"Controle\", \"Tratamento\"])\n",
    "\n",
    "sns.boxplot(x=\"is_target\", y=\"frequency\", data=users_pdf, ax=axes[1])\n",
    "axes[1].set_title(\"Pedidos por Usuário\")\n",
    "axes[1].set_xticklabels([\"Controle\", \"Tratamento\"])\n",
    "\n",
    "sns.boxplot(x=\"is_target\", y=\"aov_user\", data=users_pdf, ax=axes[2])\n",
    "axes[2].set_title(\"AOV (Ticket Médio por Usuário)\")\n",
    "axes[2].set_xticklabels([\"Controle\", \"Tratamento\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Barras comparando médias\n",
    "metrics_means = users_pdf.groupby(\"is_target\")[[\"monetary\",\"frequency\",\"aov_user\"]].mean().reset_index()\n",
    "metrics_means[\"is_target\"] = metrics_means[\"is_target\"].map({0:\"Controle\",1:\"Tratamento\"})\n",
    "\n",
    "metrics_means.plot(x=\"is_target\", kind=\"bar\", figsize=(10,6))\n",
    "plt.title(\"Médias por Grupo (GMV, Pedidos, AOV)\")\n",
    "plt.ylabel(\"Valor médio\")\n",
    "plt.show()\n",
    "\n",
    "# Histograma de pedidos por usuário\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(users_pdf[users_pdf[\"is_target\"]==0][\"frequency\"], bins=30, color=\"blue\", label=\"Controle\", stat=\"density\", alpha=0.5)\n",
    "sns.histplot(users_pdf[users_pdf[\"is_target\"]==1][\"frequency\"], bins=30, color=\"red\", label=\"Tratamento\", stat=\"density\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title(\"Distribuição de Pedidos por Usuário\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec43eae",
   "metadata": {},
   "source": [
    "### Métricas por grupo\n",
    "\n",
    "Premissas:\n",
    "* Valor do cupom: R$ 10,00\n",
    "    *  Pago integralmente pelo iFood\n",
    "* Taxa de conversão: 25%\n",
    "* Take rate: 23%\n",
    "\n",
    "Dada a distribuição assimétrica dos dados, com muitos outliers, evidenciada pelos gráficos, optou-se por utilizar métricas robustas (medianas, p95, heavy users) para a análise de impacto. Métricas robustas ajudam a evitar decisões enviesadas por outliers, garantindo que o ROI/LTV:CAC seja interpretado à luz do comportamento da maioria dos usuários. Métricas baseadas em médias também são apresentadas para comparação, mas com cautela, pois podem ser influenciadas por valores extremos. O relatório final incluirá somente métricas robustas e testes estatísticos apropriados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae39c78a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Resumo por grupo (descrição em Spark)\n",
    "ab_summary_spark = compute_ab_summary(users_silver)\n",
    "ab_summary_spark.show(truncate=False)\n",
    "\n",
    "# Métricas robustas (mediana, p95, heavy)\n",
    "robust_df = compute_robust_metrics(users_pdf, heavy_threshold=3)\n",
    "display(robust_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6aa7cc",
   "metadata": {},
   "source": [
    "### Testes de significância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501af56c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Teste paramétrico\n",
    "ttest_out = run_ab_tests(users_pdf) \n",
    "\n",
    "# Teste não-paramétrico\n",
    "mw_out    = run_nonparam_tests(users_pdf)  \n",
    "\n",
    "print(\"Welch t-test:\", ttest_out)\n",
    "print(\"Mann–Whitney:\", mw_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54476f50",
   "metadata": {},
   "source": [
    "### Viabilidade financeira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ffdc1b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "finance = financial_viability(\n",
    "    users_pdf,\n",
    "    take_rate=0.23,\n",
    "    coupon_cost=10.0,\n",
    "    redemption_rate=0.30, \n",
    ")\n",
    "finance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
