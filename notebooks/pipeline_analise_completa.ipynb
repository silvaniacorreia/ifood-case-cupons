{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe50670",
   "metadata": {},
   "source": [
    "# Análise Completa - Case Ifood: Teste A/B Estratégia de Cupons\n",
    "\n",
    "Notebook único para orquestrar as tarefas de execução de *setup*, **ETL** e análise dos dados, integrando os diferentes módulos do repositório de origem:\n",
    "\n",
    "- Clona/atualiza o repositório do projeto, com as dependências, no Colab\n",
    "- Instala dependências e faz o **download** dos dados brutos\n",
    "- Sobe Spark e executa o **ETL** (orders/consumers/restaurants + mapa A/B)\n",
    "- Mantém `orders_silver` e `users_silver` em memória\n",
    "- Realiza a análise exploratória dos dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46b6e4",
   "metadata": {},
   "source": [
    "## Configuração do Ambiente e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc5c4c",
   "metadata": {},
   "source": [
    "### Configuração de Ambiente e Download de Dados Brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daddc1e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "GITHUB_USER = \"silvaniacorreia\"\n",
    "REPO_NAME   = \"ifood-case-cupons\"\n",
    "REPO_URL    = f\"https://github.com/{GITHUB_USER}/{REPO_NAME}.git\"\n",
    "\n",
    "def run(cmd):\n",
    "    print(\">\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "# clonar/atualizar repositório\n",
    "ROOT = Path(\"/content\")\n",
    "PROJECT_DIR = ROOT / REPO_NAME\n",
    "if not PROJECT_DIR.exists():\n",
    "    run([\"git\", \"clone\", REPO_URL, str(PROJECT_DIR)])\n",
    "else:\n",
    "    os.chdir(PROJECT_DIR)\n",
    "    run([\"git\", \"fetch\", \"--all\"])\n",
    "    run([\"git\", \"reset\", \"--hard\", \"origin/main\"])\n",
    "    run([\"git\", \"checkout\", \"main\"])\n",
    "    run([\"git\", \"pull\", \"origin\", \"main\"])\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "# dependências + doewnload bases de dados\n",
    "run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\", \"--no-cache-dir\"])\n",
    "run([sys.executable, \"scripts/download_data.py\"])\n",
    "\n",
    "# sys.path\n",
    "if str(PROJECT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_DIR))\n",
    "print(\"✔️ Bootstrap concluído. Projeto:\", PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f4bcb",
   "metadata": {},
   "source": [
    "### Iniciando o Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66ab3e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import load_settings, get_spark\n",
    "\n",
    "s = load_settings()  \n",
    "extra = dict(getattr(s.runtime.spark, \"conf\", {}) or {})\n",
    "extra.setdefault(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "spark = get_spark(\n",
    "    app_name=s.runtime.spark.app_name,\n",
    "    shuffle_partitions=s.runtime.spark.shuffle_partitions,\n",
    "    extra_conf=extra,\n",
    ")\n",
    "print(\"✔️ Spark ativo - versão:\", spark.version)\n",
    "spark.range(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5aaf2e",
   "metadata": {},
   "source": [
    "### Análises Pré-Flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc9f02",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Checagens dados brutos\n",
    "from src.checks import preflight\n",
    "from pprint import pprint\n",
    "\n",
    "rep = preflight(s.data.raw_dir, strict=False)\n",
    "print(\"Pré-flight (resumo):\")\n",
    "pprint({\n",
    "    \"raw_dir\": rep[\"raw_dir\"],\n",
    "    \"orders_format_guess\": rep[\"orders_format_guess\"],\n",
    "    \"files\": {k: {kk: vv for kk, vv in v.items() if kk in (\"exists\",\"size_bytes\",\"gzip_ok\",\"tar_ok\")} for k, v in rep[\"files\"].items()},\n",
    "    \"ab_csv_candidates\": rep[\"ab_csv_candidates\"][:3],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc2464",
   "metadata": {},
   "source": [
    "### ETL (Extração, Transformação e Carga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c1918c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src import etl, checks\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "\n",
    "def _get_exp_window(s):\n",
    "    \"\"\"\n",
    "    Lê a janela do experimento a partir das configurações. Caso não exista, utiliza inferência automática.\n",
    "\n",
    "    Parâmetros:\n",
    "        s: Objeto de configurações carregado.\n",
    "\n",
    "    Retorna:\n",
    "        Tuple[str, str, bool]: Data de início, data de fim e flag de inferência automática.\n",
    "    \"\"\"\n",
    "    win = getattr(s.analysis, \"experiment_window\", None)\n",
    "    if isinstance(win, dict):\n",
    "        start = win.get(\"start\")\n",
    "        end   = win.get(\"end\")\n",
    "    else:\n",
    "        start = None\n",
    "        end   = None\n",
    "    auto = bool(getattr(s.analysis, \"auto_infer_window\", True))\n",
    "    return start, end, auto\n",
    "\n",
    "start, end, auto = _get_exp_window(s)\n",
    "\n",
    "# Leitura dos dados brutos\n",
    "orders, consumers, restaurants, abmap = etl.load_raw(spark, s.data.raw_dir)\n",
    "checks.profile_loaded(orders, consumers, restaurants, abmap, n=5)\n",
    "\n",
    "# Limpeza e conformidade dos dados\n",
    "df = etl.clean_and_conform(\n",
    "    orders, consumers, restaurants, abmap,\n",
    "    business_tz=getattr(s.analysis, \"business_tz\", \"America/Sao_Paulo\"),\n",
    "    treat_is_target_null_as_control=getattr(s.analysis, \"treat_is_target_null_as_control\", False),\n",
    "    experiment_start=start,\n",
    "    experiment_end=end,\n",
    "    auto_infer_window=auto,\n",
    "    use_quantile_window=True,     \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Ajustes finais e agregações para análise\n",
    "orders_silver = etl.build_orders_silver(df)\n",
    "orders_silver = etl.enrich_orders_for_analysis(orders_silver)\n",
    "users_silver  = etl.build_user_aggregates(orders_silver, start, end)\n",
    "\n",
    "# Cálculo de recência com base no último timestamp observado\n",
    "ref_ts = orders_silver.agg(F.max(\"event_ts_utc\")).first()[0]\n",
    "users_silver = users_silver.withColumn(\"recency\", F.datediff(F.lit(ref_ts), F.col(\"last_order\")))\n",
    "\n",
    "# Salvar resultados em formato Parquet (opcional)\n",
    "SAVE_PARQUET = False\n",
    "if SAVE_PARQUET:\n",
    "    (\n",
    "        orders_silver\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .partitionBy(\"event_date_brt\")\n",
    "        .parquet(f\"{s.data.processed_dir}/orders_silver.parquet\")\n",
    "    )\n",
    "    users_silver.write.mode(\"overwrite\").parquet(f\"{s.data.processed_dir}/users_silver.parquet\")\n",
    "\n",
    "# Contagem de linhas para validação\n",
    "print(\"orders_silver:\", orders_silver.count(), \"linhas\")\n",
    "print(\"users_silver :\", users_silver.count(), \"linhas\")\n",
    "\n",
    "# Exibição de amostras para validação\n",
    "print(\"Aviso: toPandas falhou, mostrando via Spark .show()\")\n",
    "orders_silver.show(5, truncate=False)\n",
    "users_silver.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b8d32d",
   "metadata": {},
   "source": [
    "### Checagem dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d78d984",
   "metadata": {},
   "source": [
    "Foram investigadas duplicatas semânticas na fato (IDs diferentes com mesmo cliente/loja/tempo/valor). Como apenas 1 caso foi encontrado, o que gera efeito desprezível, não foi aplicada a deduplicação adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4388b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def check_post_etl(\n",
    "    orders_silver,\n",
    "    users_silver,\n",
    "    *,\n",
    "    light: bool = True,\n",
    "    key_cols: list[str] | None = None,\n",
    "    sample_frac: float = 0.001,\n",
    "    preview_rows: int = 5,\n",
    "    use_pandas_preview: bool = False,\n",
    "    check_semantic_dups: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Executa checagens leves pós-ETL para registro no Colab.\n",
    "    - light=True: nulos apenas em colunas-chave e previews por sample.\n",
    "    - light=False: nulos em todas as colunas (lento).\n",
    "    - check_semantic_dups: investiga duplicatas semânticas na fato (lento moderado).\n",
    "    \"\"\"\n",
    "    if key_cols is None:\n",
    "        key_cols = [\n",
    "            \"order_id\", \"customer_id\", \"merchant_id\",\n",
    "            \"event_ts_utc\", \"order_total_amount\",\n",
    "            \"is_target\", \"price_range\", \"language\", \"active\",\n",
    "            \"delivery_time_imputed\", \"minimum_order_value_imputed\",\n",
    "        ]\n",
    "    key_cols = [c for c in key_cols if c in orders_silver.columns]\n",
    "\n",
    "    print(\"Faixa de datas (UTC) em orders_silver:\")\n",
    "    orders_silver.agg(\n",
    "        F.min(\"event_ts_utc\").alias(\"min_utc\"),\n",
    "        F.max(\"event_ts_utc\").alias(\"max_utc\"),\n",
    "    ).show(truncate=False)\n",
    "\n",
    "    print(\"Split A/B (users):\")\n",
    "    users_silver.groupBy(\"is_target\").count().orderBy(\"is_target\").show()\n",
    "\n",
    "    # Nulos em orders_silver\n",
    "    def nulls_by_col(df, cols):\n",
    "        exprs = [F.sum(F.col(c).isNull().cast(\"int\")).alias(c) for c in cols]\n",
    "        return df.select(exprs)\n",
    "\n",
    "    if light:\n",
    "        print(f\"Nulos (colunas-chave): {key_cols}\")\n",
    "        nulls_by_col(orders_silver, key_cols).show(truncate=False)\n",
    "    else:\n",
    "        print(\"Nulos (todas as colunas) — operação pesada:\")\n",
    "        nulls_by_col(orders_silver, orders_silver.columns).show(truncate=False)\n",
    "\n",
    "    # Duplicatas semânticas (order_ids diferentes com mesmo cliente/restaurante/ts/valor)\n",
    "    if check_semantic_dups:\n",
    "        print(\"\\nPossíveis duplicatas sistêmicas (mesmo cliente/restaurante/ts/valor, order_id distinto):\")\n",
    "        dups = (\n",
    "            orders_silver\n",
    "            .groupBy(\"customer_id\", \"merchant_id\", \"event_ts_utc\", \"order_total_amount\")\n",
    "            .agg(\n",
    "                F.countDistinct(\"order_id\").alias(\"n_orders\"),\n",
    "                F.collect_set(\"order_id\").alias(\"order_ids\"),\n",
    "            )\n",
    "            .filter(F.col(\"n_orders\") > 1)\n",
    "        )\n",
    "        total_dups = dups.count()\n",
    "        print(f\"Total de combinações com múltiplos order_id: {total_dups}\")\n",
    "        if total_dups > 0:\n",
    "            dups.select(\"customer_id\",\"merchant_id\",\"event_ts_utc\",\"order_total_amount\",\"n_orders\",\"order_ids\")\\\n",
    "                .orderBy(F.col(\"n_orders\").desc())\\\n",
    "                .show(10, truncate=False)\n",
    "\n",
    "    # Previews rápidos\n",
    "    print(\"\\nPreview orders_silver (sample leve):\")\n",
    "    orders_preview_cols = [c for c in [\n",
    "        \"price_range\",\"order_id\",\"customer_id\",\"merchant_id\",\n",
    "        \"event_ts_utc\",\"order_total_amount\",\"origin_platform\",\n",
    "        \"is_target\",\"language\",\"active\"\n",
    "    ] if c in orders_silver.columns]\n",
    "    preview_df = orders_silver.sample(False, sample_frac, seed=42).select(*orders_preview_cols)\n",
    "    if preview_df.rdd.isEmpty():\n",
    "        preview_df = orders_silver.select(*orders_preview_cols).limit(preview_rows)\n",
    "    preview_df.show(preview_rows, truncate=False)\n",
    "\n",
    "    print(\"\\nPreview users_silver (primeiras linhas):\")\n",
    "    users_preview_cols = [c for c in [\n",
    "        \"customer_id\",\"last_order\",\"frequency\",\"monetary\",\"is_target\",\"recency\"\n",
    "    ] if c in users_silver.columns]\n",
    "    users_silver.select(*users_preview_cols).show(preview_rows, truncate=False)\n",
    "\n",
    "    if use_pandas_preview:\n",
    "        try:\n",
    "            from IPython.display import display\n",
    "            display(orders_silver.limit(preview_rows).toPandas())\n",
    "            display(users_silver.limit(preview_rows).toPandas())\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "check_post_etl(orders_silver, users_silver, light=True, check_semantic_dups=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db6755",
   "metadata": {},
   "source": [
    "## A/B de cupons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe62f8c6",
   "metadata": {},
   "source": [
    "### Visualizações para exploração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d6442",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.analysis_ab import (\n",
    "    compute_ab_summary,\n",
    "    compute_robust_metrics_spark,\n",
    "    collect_user_level_for_tests,\n",
    "    run_ab_tests,\n",
    "    run_nonparam_tests,\n",
    "    financial_viability\n",
    ")\n",
    "from src.viz_ab import (\n",
    "    plot_group_bars, \n",
    "    plot_ab_box, \n",
    "    plot_ab_hist_overlay, \n",
    "    save_table_csv\n",
    ")\n",
    "\n",
    "settings = load_settings(\"config/settings.yaml\")\n",
    "\n",
    "# Amostragem \n",
    "SAMPLE_FRAC = 0.15    \n",
    "MAX_ROWS    = 100_000  \n",
    "CLIP_P      = 0.01     \n",
    "\n",
    "users_pdf = collect_user_level_for_tests(users_silver, sample_frac=0.15, seed=42)\n",
    "\n",
    "if len(users_pdf) > MAX_ROWS:\n",
    "    users_pdf = users_pdf.sample(n=MAX_ROWS, random_state=42)\n",
    "\n",
    "if \"aov_user\" not in users_pdf.columns:\n",
    "    users_pdf[\"aov_user\"] = users_pdf[\"monetary\"] / users_pdf[\"frequency\"].replace({0: np.nan})\n",
    "\n",
    "# Recorte de cauda para visual \n",
    "q_low  = users_pdf[[\"monetary\",\"frequency\",\"aov_user\"]].quantile(CLIP_P)\n",
    "q_high = users_pdf[[\"monetary\",\"frequency\",\"aov_user\"]].quantile(1-CLIP_P)\n",
    "for col in [\"monetary\",\"frequency\",\"aov_user\"]:\n",
    "    users_pdf[col] = users_pdf[col].clip(q_low[col], q_high[col])\n",
    "\n",
    "users_pdf[\"grupo\"] = users_pdf[\"is_target\"].map({0:\"Controle\", 1:\"Tratamento\"}).astype(\"category\")\n",
    "\n",
    "# Boxplots\n",
    "sns.set_theme()\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "sns.boxplot(x=\"grupo\", y=\"monetary\", data=users_pdf, ax=axes[0], showfliers=False)\n",
    "axes[0].set_title(\"GMV por Usuário (amostra, caudas recortadas)\")\n",
    "sns.boxplot(x=\"grupo\", y=\"frequency\", data=users_pdf, ax=axes[1], showfliers=False)\n",
    "axes[1].set_title(\"Pedidos por Usuário (amostra)\")\n",
    "sns.boxplot(x=\"grupo\", y=\"aov_user\", data=users_pdf, ax=axes[2], showfliers=False)\n",
    "axes[2].set_title(\"AOV por Usuário (amostra)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Barras de médias (amostra)\n",
    "metrics_means = (users_pdf\n",
    "                 .groupby(\"grupo\")[[\"monetary\",\"frequency\",\"aov_user\"]]\n",
    "                 .mean()\n",
    "                 .reset_index())\n",
    "ax = metrics_means.plot(x=\"grupo\", kind=\"bar\", figsize=(10,6))\n",
    "plt.title(\"Médias por Grupo (GMV, Pedidos, AOV) — amostra\")\n",
    "plt.ylabel(\"Valor médio (amostra)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Histogramas\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(users_pdf.loc[users_pdf[\"grupo\"]==\"Controle\",\"frequency\"],\n",
    "             bins=30, stat=\"density\", alpha=0.5, label=\"Controle\")\n",
    "sns.histplot(users_pdf.loc[users_pdf[\"grupo\"]==\"Tratamento\",\"frequency\"],\n",
    "             bins=30, stat=\"density\", alpha=0.5, label=\"Tratamento\")\n",
    "plt.legend(); plt.title(\"Distribuição de Pedidos por Usuário — amostra (caudas recortadas)\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec43eae",
   "metadata": {},
   "source": [
    "### Métricas por grupo\n",
    "\n",
    "Premissas:\n",
    "* Valor do cupom: R$ 10,00\n",
    "    *  Pago integralmente pelo iFood\n",
    "* Taxa de resgate: 30%\n",
    "* Take rate: 23%\n",
    "\n",
    "Dada a distribuição assimétrica dos dados evidenciada pelos gráficos, com muitos outliers, optou-se por utilizar métricas robustas (medianas, p95, heavy users) para a análise de impacto. Métricas robustas ajudam a evitar decisões enviesadas por outliers, garantindo que sejam interpretadas à luz do comportamento da maioria dos usuários. Métricas baseadas em médias também são apresentadas para comparação, mas com cautela, pois podem ser influenciadas por valores extremos. O relatório final incluirá somente métricas robustas e testes estatísticos apropriados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae39c78a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "out_ab = \"outputs/ab\"\n",
    "\n",
    "# Resumo por grupo (descrição em Spark)\n",
    "ab_summary_spark = compute_ab_summary(users_silver)\n",
    "ab_summary_spark.show(truncate=False)\n",
    "ab_summary_pdf = ab_summary_spark.toPandas()\n",
    "save_table_csv(ab_summary_pdf, out_ab, \"ab_means\")\n",
    "\n",
    "# Métricas robustas (mediana, p95, heavy)\n",
    "robust_spark = compute_robust_metrics_spark(users_silver, heavy_threshold=3)\n",
    "robust_pdf = robust_spark.toPandas()\n",
    "save_table_csv(robust_pdf, out_ab, \"ab_robust\")\n",
    "display(robust_pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6aa7cc",
   "metadata": {},
   "source": [
    "### Testes de significância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501af56c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Teste paramétrico\n",
    "ttest_out = run_ab_tests(users_pdf) \n",
    "\n",
    "# Teste não-paramétrico\n",
    "mw_out = run_nonparam_tests(users_pdf)  \n",
    "\n",
    "print(\"Welch t-test:\", ttest_out)\n",
    "print(\"Mann–Whitney:\", mw_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54476f50",
   "metadata": {},
   "source": [
    "### Viabilidade financeira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ffdc1b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "res_fin = financial_viability(\n",
    "    users_silver,\n",
    "    take_rate=s.finance.take_rate,\n",
    "    coupon_cost=s.finance.coupon_cost_default,\n",
    "    redemption_rate=0.30, \n",
    ")\n",
    "\n",
    "print(\"Viabilidade financeira:\")\n",
    "display(res_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6273ac",
   "metadata": {},
   "source": [
    "### Visualizações para relatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01590dca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.viz_ab import plot_group_bars, plot_ab_box, plot_ab_hist_overlay\n",
    "\n",
    "# barras com médias\n",
    "plot_group_bars(\n",
    "    ab_summary_pdf.rename(columns={\"aov\":\"aov_user\"}),\n",
    "    metrics=[\"gmv_user\",\"pedidos_user\",\"aov_user\"],\n",
    "    labels_map={\"gmv_user\":\"GMV/usuário\",\"pedidos_user\":\"Pedidos/usuário\",\"aov_user\":\"AOV\"},\n",
    "    outdir=\"outputs/ab\", fname=\"bars_means\", title=\"Médias por grupo\"\n",
    ")\n",
    "\n",
    "# barras com medianas\n",
    "plot_group_bars(\n",
    "    robust_pdf.rename(columns={\n",
    "        \"median_gmv_user\":\"GMV mediano\",\n",
    "        \"median_pedidos_user\":\"Pedidos medianos\",\n",
    "        \"median_aov_user\":\"AOV mediano\"\n",
    "    })[[\"is_target\",\"GMV mediano\",\"Pedidos medianos\",\"AOV mediano\"]],\n",
    "    metrics=[\"GMV mediano\",\"Pedidos medianos\",\"AOV mediano\"],\n",
    "    outdir=\"outputs/ab\", fname=\"bars_medians\", title=\"Métricas robustas por grupo\"\n",
    ")\n",
    "\n",
    "# distribuições com users_pdf (amostra)\n",
    "for metric in [\"monetary\",\"frequency\",\"aov_user\"]:\n",
    "    plot_ab_box(users_pdf, metric, outdir=\"outputs/ab\", fname=f\"box_{metric}\", clip_p=0.01)\n",
    "    plot_ab_hist_overlay(users_pdf, metric, outdir=\"outputs/ab\", fname=f\"hist_{metric}\", clip_p=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e7587c",
   "metadata": {},
   "source": [
    "## Análise de Segmentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3ff804",
   "metadata": {},
   "source": [
    "### Construção de segmentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c72251b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.analysis_segments import build_rfm_buckets, ab_metrics_by_segment\n",
    "from src.viz_segments import to_pandas_spark, save_table_csv\n",
    "\n",
    "# RFM\n",
    "users_with_rfm = build_rfm_buckets(users_silver)\n",
    "\n",
    "sample_ids_spark = spark.createDataFrame(\n",
    "    users_pdf[[\"customer_id\"]].drop_duplicates()\n",
    ")\n",
    "rfm_small = (\n",
    "    users_with_rfm\n",
    "    .join(sample_ids_spark, \"customer_id\", \"inner\")\n",
    "    .select(\"customer_id\",\"rfm_segment\")\n",
    "    .toPandas()\n",
    ")\n",
    "users_pdf = users_pdf.merge(rfm_small, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "# Heavy / New / Platform / RFM\n",
    "ab_heavy = ab_metrics_by_segment(users_silver, segment_col=\"heavy_user\")\n",
    "ab_new   = ab_metrics_by_segment(users_silver, segment_col=\"is_new_customer\")\n",
    "ab_plat  = ab_metrics_by_segment(users_silver, segment_col=\"origin_platform\")\n",
    "ab_rfm   = ab_metrics_by_segment(users_with_rfm, segment_col=\"rfm_segment\", top_k_segments=10)\n",
    "\n",
    "ab_heavy_pd = to_pandas_spark(ab_heavy)\n",
    "ab_new_pd   = to_pandas_spark(ab_new)\n",
    "ab_plat_pd  = to_pandas_spark(ab_plat)\n",
    "ab_rfm_pd   = to_pandas_spark(ab_rfm)\n",
    "\n",
    "outdir = \"outputs/segments\"\n",
    "save_table_csv(ab_heavy_pd, outdir, \"ab_heavy_summary\")\n",
    "save_table_csv(ab_new_pd,   outdir, \"ab_new_summary\")\n",
    "save_table_csv(ab_plat_pd,  outdir, \"ab_platform_summary\")\n",
    "save_table_csv(ab_rfm_pd,   outdir, \"ab_rfm_summary\")\n",
    "ab_heavy_pd, ab_new_pd.head(), ab_plat_pd.head(), ab_rfm_pd.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f8d84",
   "metadata": {},
   "source": [
    "### Testes e métricas robustas por segmento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a7ed5a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.analysis_segments import robust_metrics_by_segment, nonparam_tests_by_segment, finance_by_segment\n",
    "\n",
    "SEG_COLS_PANDAS = [c for c in [\"heavy_user\",\"is_new_customer\",\"origin_platform\",\"rfm_segment\"] if c in users_pdf.columns]\n",
    "SEG_COLS_SPARK  = [c for c in [\"heavy_user\",\"origin_platform\",\"rfm_segment\"] if c in users_silver.columns]  \n",
    "\n",
    "# tabelas robustas (medianas/p95/heavy rate) (amostra)\n",
    "robust_tables = {\n",
    "    seg: robust_metrics_by_segment(users_pdf, segment_col=seg, heavy_threshold=3)\n",
    "    for seg in SEG_COLS_PANDAS\n",
    "}\n",
    "\n",
    "# testes não-paramétricos (Mann–Whitney) (amostra)\n",
    "mw_tests = {\n",
    "    seg: nonparam_tests_by_segment(users_pdf, segment_col=seg)\n",
    "    for seg in SEG_COLS_PANDAS\n",
    "}\n",
    "\n",
    "# financeiro por segmento EM SPARK (100% da base)\n",
    "finance_tables = {\n",
    "    seg: finance_by_segment(\n",
    "        users_silver, segment_col=seg,\n",
    "        take_rate=0.23, coupon_cost=10.0, redemption_rate=0.30\n",
    "    )\n",
    "    for seg in SEG_COLS_SPARK\n",
    "}\n",
    "\n",
    "# Imprimir testes\n",
    "mw_tests.get(\"heavy_user\"), list(finance_tables.get(\"heavy_user\", {}).items())[:2]\n",
    "mw_tests.get(\"origin_platform\"), list(finance_tables.get(\"origin_platform\", {}).items())[:2]\n",
    "mw_tests.get(\"rfm_segment\"), list(finance_tables.get(\"rfm_segment\", {}).items())[:2]\n",
    "print(\"Teste Mann-Whitney:\", mw_tests.get(\"heavy_user\"))\n",
    "print(\"Teste Mann-Whitney:\", mw_tests.get(\"origin_platform\"))\n",
    "print(\"Teste Mann-Whitney:\", mw_tests.get(\"rfm_segment\"))\n",
    "\n",
    "# salvar tabelas \n",
    "outdir = \"outputs/tables_segments\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# robust_* (um CSV por segmento)\n",
    "for seg, df in robust_tables.items():\n",
    "    df.to_csv(f\"{outdir}/robust_{seg}.csv\", index=False)\n",
    "\n",
    "# finance_* (dict -> DataFrame por segmento)\n",
    "for seg, d in finance_tables.items():\n",
    "    if d:  # pode estar vazio se faltar um dos grupos no segmento\n",
    "        pd.DataFrame.from_dict(d, orient=\"index\").reset_index(names=[seg]).to_csv(\n",
    "            f\"{outdir}/finance_{seg}.csv\", index=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe798458",
   "metadata": {},
   "source": [
    "### Visualização de Segmentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2ef14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from src.viz_segments import plot_bars_from_robust, plot_rate_by_segment\n",
    "\n",
    "figdir = \"outputs/figs_segments\"\n",
    "Path(figdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# DFs robustos (prioriza o que já está em memória; se não houver, lê dos CSVs)\n",
    "def get_robust_df(key, fallback_path):\n",
    "    if \"robust_tables\" in globals() and key in robust_tables:\n",
    "        return robust_tables[key]\n",
    "    return pd.read_csv(fallback_path)\n",
    "\n",
    "robust_heavy_pd = get_robust_df(\"heavy_user\",      \"outputs/tables_segments/robust_heavy_user.csv\")\n",
    "robust_plat_pd  = get_robust_df(\"origin_platform\", \"outputs/tables_segments/robust_origin_platform.csv\")\n",
    "robust_rfm_pd   = get_robust_df(\"rfm_segment\",     \"outputs/tables_segments/robust_rfm_segment.csv\")\n",
    "\n",
    "# Barras de MEDIANAS por segmento\n",
    "plot_bars_from_robust(\n",
    "    robust_heavy_pd, \"segment\", which=\"median\",\n",
    "    title=\"Medianas por segmento (Heavy vs Não-heavy)\",\n",
    "    outdir=figdir, fname=\"bars_heavy_medianas\"\n",
    ")\n",
    "\n",
    "plot_bars_from_robust(\n",
    "    robust_plat_pd, \"segment\", which=\"median\",\n",
    "    title=\"Medianas por segmento (Plataforma)\",\n",
    "    outdir=figdir, fname=\"bars_platform_medianas\"\n",
    ")\n",
    "\n",
    "# Barras de P95 \n",
    "plot_bars_from_robust(\n",
    "    robust_heavy_pd, \"segment\", which=\"p95\",\n",
    "    title=\"p95 por segmento (Heavy vs Não-heavy)\",\n",
    "    outdir=figdir, fname=\"bars_heavy_p95\"\n",
    ")\n",
    "\n",
    "# % de heavy users (≥3) por segmento\n",
    "plot_rate_by_segment(\n",
    "    robust_plat_pd, \"segment\",\n",
    "    title=\"% de heavy users (≥3) por plataforma\",\n",
    "    outdir=figdir, fname=\"bars_platform_heavy_rate\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd1744",
   "metadata": {},
   "source": [
    "### Break-even do cupom \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccc3cce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Parâmetros \n",
    "try:\n",
    "    TAKE_RATE = float(s.finance.take_rate)\n",
    "    COUPON_COST = float(s.finance.coupon_cost_default)\n",
    "except Exception:\n",
    "    TAKE_RATE = 0.23\n",
    "    COUPON_COST = 10.0\n",
    "\n",
    "REDEMPTION = 0.30  \n",
    "OUTDIR = \"outputs/tables_segments\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "def break_even_table_spark(\n",
    "    users_silver,\n",
    "    *,\n",
    "    take_rate: float,\n",
    "    coupon_cost: float,\n",
    "    redemption_rate: float,\n",
    "    segment_col: str | None = None,\n",
    "    id_col: str = \"customer_id\",\n",
    "    group_col: str = \"is_target\",\n",
    "    monetary_col: str = \"monetary\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calcula, no Spark, o uplift de GMV por usuário tratado e compara com o break-even.\n",
    "    Se segment_col=None, retorna 1 linha (overall). Caso contrário, 1 linha por segmento.\n",
    "    \"\"\"\n",
    "    needed = [id_col, group_col, monetary_col]\n",
    "    if segment_col:\n",
    "        needed.append(segment_col)\n",
    "    missing = [c for c in needed if c not in users_silver.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Colunas ausentes no users_silver: {missing}\")\n",
    "\n",
    "    by = [segment_col, group_col] if segment_col else [group_col]\n",
    "    ab = (\n",
    "        users_silver\n",
    "        .groupBy(*by)\n",
    "        .agg(\n",
    "            F.countDistinct(F.col(id_col)).alias(\"usuarios\"),\n",
    "            F.avg(F.col(monetary_col)).alias(\"gmv_user\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    cond_ctrl = (F.col(group_col) == 0)\n",
    "    cond_trat = (F.col(group_col) == 1)\n",
    "\n",
    "    if segment_col:\n",
    "        ctrl = ab.filter(cond_ctrl).select(\n",
    "            F.col(segment_col).alias(\"segment\"),\n",
    "            F.col(\"usuarios\").alias(\"usuarios_ctrl\"),\n",
    "            F.col(\"gmv_user\").alias(\"gmv_ctrl\")\n",
    "        )\n",
    "        trat = ab.filter(cond_trat).select(\n",
    "            F.col(segment_col).alias(\"segment\"),\n",
    "            F.col(\"usuarios\").alias(\"usuarios_trat\"),\n",
    "            F.col(\"gmv_user\").alias(\"gmv_trat\")\n",
    "        )\n",
    "        joined = trat.join(ctrl, on=\"segment\", how=\"inner\")\n",
    "    else:\n",
    "        # cria uma chave única \"ALL\"\n",
    "        ctrl = ab.filter(cond_ctrl).select(\n",
    "            F.lit(\"ALL\").alias(\"segment\"),\n",
    "            F.col(\"usuarios\").alias(\"usuarios_ctrl\"),\n",
    "            F.col(\"gmv_user\").alias(\"gmv_ctrl\")\n",
    "        )\n",
    "        trat = ab.filter(cond_trat).select(\n",
    "            F.lit(\"ALL\").alias(\"segment\"),\n",
    "            F.col(\"usuarios\").alias(\"usuarios_trat\"),\n",
    "            F.col(\"gmv_user\").alias(\"gmv_trat\")\n",
    "        )\n",
    "        joined = trat.join(ctrl, on=\"segment\", how=\"inner\")\n",
    "\n",
    "    uplift_needed = (coupon_cost * redemption_rate) / take_rate if take_rate > 0 else None\n",
    "\n",
    "    joined = (\n",
    "        joined\n",
    "        .withColumn(\"uplift_gmv_user\", F.col(\"gmv_trat\") - F.col(\"gmv_ctrl\"))\n",
    "        .withColumn(\"uplift_needed\", F.lit(float(uplift_needed) if uplift_needed is not None else None))\n",
    "        .withColumn(\"gap_uplift\", F.col(\"uplift_gmv_user\") - F.col(\"uplift_needed\"))\n",
    "        .withColumn(\"receita_total\", F.lit(take_rate) * F.col(\"uplift_gmv_user\") * F.col(\"usuarios_trat\"))\n",
    "        .withColumn(\"custo_total\", F.lit(coupon_cost * redemption_rate) * F.col(\"usuarios_trat\"))\n",
    "        .withColumn(\"lucro_total\", F.col(\"receita_total\") - F.col(\"custo_total\"))\n",
    "        .withColumn(\"lucro_por_usuario\", F.when(F.col(\"usuarios_trat\") > 0, F.col(\"lucro_total\")/F.col(\"usuarios_trat\")).otherwise(F.lit(0.0)))\n",
    "        .withColumn(\"roi_percent\", F.when(F.col(\"custo_total\") > 0, F.col(\"lucro_total\")/F.col(\"custo_total\")).otherwise(F.lit(None)))\n",
    "        .withColumn(\"status\", F.when(F.col(\"lucro_por_usuario\") >= 0, F.lit(\"OK\")).otherwise(F.lit(\"NEG\")))\n",
    "    )\n",
    "\n",
    "    cols = [\n",
    "        \"segment\",\"usuarios_trat\",\"gmv_ctrl\",\"gmv_trat\",\"uplift_gmv_user\",\n",
    "        \"uplift_needed\",\"gap_uplift\",\"receita_total\",\"custo_total\",\"lucro_total\",\n",
    "        \"lucro_por_usuario\",\"roi_percent\",\"status\"\n",
    "    ]\n",
    "    pdf = joined.select(*cols).toPandas()\n",
    "\n",
    "    for c in [\"gmv_ctrl\",\"gmv_trat\",\"uplift_gmv_user\",\"uplift_needed\",\"gap_uplift\",\"lucro_por_usuario\"]:\n",
    "        if c in pdf.columns:\n",
    "            pdf[c] = pdf[c].astype(float).round(2)\n",
    "    for c in [\"receita_total\",\"custo_total\",\"lucro_total\"]:\n",
    "        if c in pdf.columns:\n",
    "            pdf[c] = pdf[c].astype(float).round(0)\n",
    "    if \"roi_percent\" in pdf.columns:\n",
    "        pdf[\"roi_percent\"] = pdf[\"roi_percent\"].astype(float).round(3)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "# Tabelas de break-even (overall e por segmento)\n",
    "be_overall = break_even_table_spark(\n",
    "    users_silver,\n",
    "    take_rate=TAKE_RATE, coupon_cost=COUPON_COST, redemption_rate=REDEMPTION,\n",
    "    segment_col=None\n",
    ")\n",
    "be_heavy = break_even_table_spark(\n",
    "    users_silver,\n",
    "    take_rate=TAKE_RATE, coupon_cost=COUPON_COST, redemption_rate=REDEMPTION,\n",
    "    segment_col=\"heavy_user\" if \"heavy_user\" in users_silver.columns else None\n",
    ")\n",
    "be_platform = break_even_table_spark(\n",
    "    users_silver,\n",
    "    take_rate=TAKE_RATE, coupon_cost=COUPON_COST, redemption_rate=REDEMPTION,\n",
    "    segment_col=\"origin_platform\" if \"origin_platform\" in users_silver.columns else None\n",
    ")\n",
    "\n",
    "# Salva CSVs\n",
    "be_overall.to_csv(f\"{OUTDIR}/break_even_overall.csv\", index=False)\n",
    "if not be_heavy.empty:\n",
    "    be_heavy.to_csv(f\"{OUTDIR}/break_even_heavy_user.csv\", index=False)\n",
    "if not be_platform.empty:\n",
    "    be_platform.to_csv(f\"{OUTDIR}/break_even_origin_platform.csv\", index=False)\n",
    "\n",
    "display(be_overall)\n",
    "display(be_heavy)\n",
    "display(be_platform)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
