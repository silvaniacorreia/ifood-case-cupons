{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ed45101",
   "metadata": {},
   "source": [
    "# ETL (Extract, Transform, Load)\n",
    "\n",
    "Este notebook realiza o processo de ETL (Extract, Transform, Load) de dados de pedidos, consumidores e restaurantes, com o objetivo de preparar e analisar dados para experimentos de negócio. As principais etapas incluem:\n",
    "\n",
    "- **Carregamento de Dados Brutos:** Utiliza funções utilitárias para carregar dados brutos de pedidos, consumidores, restaurantes e mapeamento de IDs.\n",
    "- **Limpeza e Conformação:** Aplica regras de limpeza, tratamento de timezone e conformação dos dados para garantir consistência e qualidade.\n",
    "- **Construção de Camadas Silver:** Gera tabelas intermediárias (\"silver\") de pedidos e usuários, agregando informações relevantes como recência, frequência e valor monetário.\n",
    "- **Análises Exploratórias:** Realiza inspeções de schema, contagem de linhas, análise de nulos, faixas de datas, splits por grupos experimentais, distribuição de valores e estatísticas descritivas.\n",
    "- **Validações:** Executa asserts para garantir unicidade de IDs e ausência de nulos críticos.\n",
    "- **Visualizações:** Gera gráficos para explorar a distribuição dos valores de pedidos e sumariza métricas por grupo experimental.\n",
    "\n",
    "O notebook serve como base para análises e validações de experimentos, garantindo integridade e qualidade dos dados processados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb8ed53",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNABLE_TO_INFER_SCHEMA] Unable to infer schema for CSV. It must be specified manually.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m s \u001b[38;5;241m=\u001b[39m load_settings()\n\u001b[0;32m     23\u001b[0m spark \u001b[38;5;241m=\u001b[39m get_spark(app_name\u001b[38;5;241m=\u001b[39ms\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39mapp_name,\n\u001b[0;32m     24\u001b[0m                   shuffle_partitions\u001b[38;5;241m=\u001b[39ms\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39mshuffle_partitions)\n\u001b[1;32m---> 26\u001b[0m orders, consumers, restaurants, abmap \u001b[38;5;241m=\u001b[39m \u001b[43metl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m df \u001b[38;5;241m=\u001b[39m etl\u001b[38;5;241m.\u001b[39mclean_and_conform(\n\u001b[0;32m     29\u001b[0m     orders, consumers, restaurants, abmap,\n\u001b[0;32m     30\u001b[0m     business_tz\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(s\u001b[38;5;241m.\u001b[39manalysis, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbusiness_tz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmerica/Sao_Paulo\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     experiment_end\u001b[38;5;241m=\u001b[39ms\u001b[38;5;241m.\u001b[39manalysis\u001b[38;5;241m.\u001b[39mexperiment_window[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     36\u001b[0m orders_silver \u001b[38;5;241m=\u001b[39m etl\u001b[38;5;241m.\u001b[39mbuild_orders_silver(df)\n",
      "File \u001b[1;32mc:\\Users\\silva\\OneDrive\\Documentos\\portfólio\\ifood-case-cupons\\src\\etl.py:56\u001b[0m, in \u001b[0;36mload_raw\u001b[1;34m(spark, raw_dir)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ab_csv:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSV do ab_test_ref não encontrado em \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mab_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m abmap \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     53\u001b[0m     \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minferSchema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m---> 56\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mab_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m orders, consumers, restaurants, abmap\n",
      "File \u001b[1;32mc:\\Users\\silva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:740\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[1;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[1;32mc:\\Users\\silva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\silva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [UNABLE_TO_INFER_SCHEMA] Unable to infer schema for CSV. It must be specified manually."
     ]
    }
   ],
   "source": [
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "GITHUB_USER = \"silvaniacorreia\"\n",
    "REPO_NAME   = \"ifood-case-cupons\"\n",
    "\n",
    "IN_COLAB = \"COLAB_RELEASE_TAG\" in os.environ or \"COLAB_GPU\" in os.environ\n",
    "\n",
    "if IN_COLAB:\n",
    "    PROJECT_DIR = Path(\"/content\") / REPO_NAME\n",
    "    os.chdir(PROJECT_DIR)\n",
    "else:\n",
    "    PROJECT_DIR = Path.cwd()\n",
    "\n",
    "if str(PROJECT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_DIR))\n",
    "\n",
    "from src.utils import load_settings, get_spark\n",
    "from src import etl\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "s = load_settings()\n",
    "spark = get_spark(app_name=s.runtime.spark.app_name,\n",
    "                  shuffle_partitions=s.runtime.spark.shuffle_partitions)\n",
    "\n",
    "orders, consumers, restaurants, abmap = etl.load_raw(spark, s.data.raw_dir)\n",
    "\n",
    "df = etl.clean_and_conform(\n",
    "    orders, consumers, restaurants, abmap,\n",
    "    business_tz=getattr(s.analysis, \"business_tz\", \"America/Sao_Paulo\"),\n",
    "    treat_is_target_null_as_control=getattr(s.analysis, \"treat_is_target_null_as_control\", False),\n",
    "    experiment_start=s.analysis.experiment_window[\"start\"],\n",
    "    experiment_end=s.analysis.experiment_window[\"end\"],\n",
    ")\n",
    "\n",
    "orders_silver = etl.build_orders_silver(df)\n",
    "orders_silver.write.mode(\"overwrite\").parquet(f\"{s.data.processed_dir}/orders_silver.parquet\")\n",
    "\n",
    "users_silver = etl.build_user_aggregates(orders_silver)\n",
    "ref_ts = orders_silver.agg(F.max(\"event_ts_utc\")).first()[0]\n",
    "users_silver = users_silver.withColumn(\"recency\", F.datediff(F.lit(ref_ts), F.col(\"last_order\")))\n",
    "users_silver.write.mode(\"overwrite\").parquet(f\"{s.data.processed_dir}/users_silver.parquet\")\n",
    "\n",
    "display(orders_silver.limit(5).toPandas())\n",
    "display(users_silver.limit(5).toPandas())\n",
    "print(\"ref_ts:\", ref_ts)\n",
    "print(\"ETL concluído com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63638957",
   "metadata": {},
   "source": [
    "## Checagens dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1811ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esquema, contagens e unicidade de chaves\n",
    "\n",
    "print(\"=== orders_silver ===\")\n",
    "orders_silver.printSchema()\n",
    "n_orders = orders_silver.count()\n",
    "n_orders_distinct = orders_silver.select(\"order_id\").distinct().count()\n",
    "print(\"linhas:\", n_orders, \"| order_id distintos:\", n_orders_distinct)\n",
    "\n",
    "print(\"\\n=== users_silver ===\")\n",
    "users_silver.printSchema()\n",
    "n_users  = users_silver.count()\n",
    "n_users_distinct = users_silver.select(\"customer_id\").distinct().count()\n",
    "print(\"linhas:\", n_users, \"| customer_id distintos:\", n_users_distinct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384b635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nulos por coluna \n",
    "\n",
    "def nulls_by_col(df):\n",
    "    exprs = [F.sum(F.col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]\n",
    "    return df.select(exprs)\n",
    "\n",
    "print(\"Nulos em orders_silver:\")\n",
    "nulls_by_col(orders_silver).show(truncate=False)\n",
    "\n",
    "print(\"Nulos em users_silver:\")\n",
    "nulls_by_col(users_silver).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ca658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faixa de datas e janela do experimento\n",
    "\n",
    "print(\"Faixa de datas (UTC) em orders_silver:\")\n",
    "orders_silver.agg(F.min(\"event_ts_utc\").alias(\"min_utc\"),\n",
    "                  F.max(\"event_ts_utc\").alias(\"max_utc\")).show()\n",
    "\n",
    "print(\"Contagem diária (BRT) por grupo:\")\n",
    "(orders_silver.groupBy(\"event_date_brt\",\"is_target\")\n",
    " .count()\n",
    " .orderBy(\"event_date_brt\",\"is_target\")\n",
    " .show(40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c970496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanceamento do A/B\n",
    "\n",
    "print(\"Split por is_target (orders):\")\n",
    "orders_silver.groupBy(\"is_target\").count().show()\n",
    "\n",
    "print(\"Split por is_target (users):\")\n",
    "users_silver.groupBy(\"is_target\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995251d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores monetários — sanity check e outliers\n",
    "\n",
    "print(\"Negativos/zero em order_total_amount:\")\n",
    "neg = orders_silver.filter(F.col(\"order_total_amount\") < 0).count()\n",
    "zero = orders_silver.filter(F.col(\"order_total_amount\") == 0).count()\n",
    "print(\"negativos:\", neg, \"| zero:\", zero)\n",
    "\n",
    "print(\"Resumo de order_total_amount:\")\n",
    "orders_silver.select(\"order_total_amount\").summary().show()\n",
    "\n",
    "print(\"Quantis aproximados (1%, 5%, 50%, 95%, 99%):\")\n",
    "q = orders_silver.approxQuantile(\"order_total_amount\", [0.01, 0.05, 0.5, 0.95, 0.99], 0.01)\n",
    "q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f500e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top outliers (visão pontual)\n",
    "\n",
    "orders_silver.orderBy(F.desc(\"order_total_amount\")).select(\n",
    "    \"order_id\",\"customer_id\",\"order_total_amount\",\"event_ts_utc\",\"is_target\"\n",
    ").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Distribuições\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pdf = (orders_silver\n",
    "       .select(\"order_total_amount\")\n",
    "       .sample(withReplacement=False, fraction=0.2, seed=42)  # 20% de amostra\n",
    "       .toPandas()\n",
    "       .dropna())\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(pdf[\"order_total_amount\"], bins=50)\n",
    "plt.title(\"Distribuição de order_total_amount (amostra)\")\n",
    "plt.xlabel(\"R$\")\n",
    "plt.ylabel(\"Contagem\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a150a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas por grupo\n",
    "\n",
    "preview = (orders_silver.groupBy(\"is_target\")\n",
    "           .agg(\n",
    "               F.count(\"*\").alias(\"n_orders\"),\n",
    "               F.sum(\"order_total_amount\").alias(\"gmv\"),\n",
    "               F.avg(\"order_total_amount\").alias(\"avg_ticket\"),\n",
    "           )\n",
    "          )\n",
    "preview.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544320f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanidade de atributos de apoio\n",
    "\n",
    "print(\"language por grupo (users):\")\n",
    "(users_silver.groupBy(\"is_target\",\"language\")\n",
    " .count()\n",
    " .orderBy(\"language\",\"is_target\")\n",
    " .show(20))\n",
    "\n",
    "print(\"active rate por grupo (users):\")\n",
    "(users_silver.groupBy(\"is_target\")\n",
    " .agg(F.avg(F.col(\"recency\").isNotNull().cast(\"double\")).alias(\"has_recency\"),\n",
    "      F.avg(F.col(\"frequency\")).alias(\"avg_freq\"),\n",
    "      F.avg(F.col(\"monetary\")).alias(\"avg_monetary\"))\n",
    " .show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c851f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checklist final do ETL\n",
    "\n",
    "assert n_orders == n_orders_distinct, \"order_id duplicado no silver de pedidos\"\n",
    "assert n_users == n_users_distinct,   \"customer_id duplicado no silver de usuários\"\n",
    "assert orders_silver.filter(F.col(\"event_ts_utc\").isNull()).count() == 0, \"event_ts_utc nulo\"\n",
    "assert users_silver.filter(F.col(\"is_target\").isNull()).count() == 0, \"is_target nulo em users\"\n",
    "print(\"✔️ ETL checks básicos OK.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
